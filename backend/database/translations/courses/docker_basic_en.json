{
    "_comment": "English translations for Docker Master Course (DockerCourseSeeder)",
    "template": {
        "title": "DockerÂÆüË∑µ„Éû„Çπ„Çø„Éº„Ç≥„Éº„Çπ",
        "description": "WSL2 + Docker DesktopÁí∞Â¢É„ÅßÂ≠¶„Å∂„ÄÅÂàùÂøÉËÄÖ„Åã„ÇâÂÆüË∑µ„Åæ„ÅßÂÆåÂÖ®ÂØæÂøú„ÅÆDocker„Ç≥„Éº„Çπ„ÄÇ„Ç≥„É≥„ÉÜ„ÉäÂåñ„Åã„ÇâCI/CD„ÄÅ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÄÅÁõ£Ë¶ñ„Åæ„Åß12ÈÄ±Èñì„ÅßÁøíÂæó„Åó„Åæ„Åô„ÄÇ"
    },
    "template_translations": {
        "DockerÂÆüË∑µ„Éû„Çπ„Çø„Éº„Ç≥„Éº„Çπ": {
            "title": "Docker Master Course",
            "description": "Complete Docker course from beginner to practical level using WSL2 + Docker Desktop environment. Master containerization, CI/CD, security, and monitoring over 12 weeks."
        },
        "DockerÂü∫Á§é": {
            "title": "Docker Master Course",
            "description": "Complete Docker course from beginner to practical level using WSL2 + Docker Desktop environment. Master containerization, CI/CD, security, and monitoring over 12 weeks."
        }
    },
    "milestones": {
        "DockerÂü∫Á§é": {
            "title": "Docker Fundamentals",
            "description": "Environment setup, Docker basic concepts, Dockerfile creation, basic commands",
            "deliverables": [
                "Complete WSL2 + Docker Desktop environment setup",
                "Run Hello World container",
                "Create Dockerfile and build custom image",
                "Master basic commands"
            ]
        },
        "Docker‰∏≠Á¥ö": {
            "title": "Docker Intermediate",
            "description": "Managing multiple containers with Volumes, Networks, Docker Compose",
            "deliverables": [
                "Use Volumes for data persistence",
                "Create and manage Networks",
                "Use Docker Compose for multi-container applications",
                "Manage environment variables and Secrets"
            ]
        },
        "Docker‰∏äÁ¥ö": {
            "title": "Docker Advanced",
            "description": "Multi-stage Build, Healthcheck, Private Registry, Security",
            "deliverables": [
                "Create optimized images with multi-stage build",
                "Implement healthchecks",
                "Set up private registry",
                "Apply security best practices"
            ]
        },
        "DockerÂÆüË∑µ": {
            "title": "Docker Practice",
            "description": "Orchestration, Monitoring, Microservices architecture",
            "deliverables": [
                "Set up orchestration with Docker Swarm",
                "Implement monitoring with Prometheus + Grafana",
                "Build Microservices + API Gateway architecture",
                "Set up logging system"
            ]
        },
        "Capstone Project": {
            "title": "Capstone Project",
            "description": "Complete E-commerce architecture + CI/CD + Production deployment",
            "deliverables": [
                "Build Full-stack E-commerce",
                "Set up GitHub Actions CI/CD",
                "Automate security scanning",
                "Complete production environment setup"
            ]
        }
    },
    "tasks": {
        "Á¨¨1ÈÄ±ÔºöÁí∞Â¢ÉÊßãÁØâ„Å®DockerÂÖ•ÈñÄ": {
            "title": "Week 1: Environment Setup and Docker Introduction",
            "description": "WSL2 + Docker Desktop setup, Docker basic concepts, architecture",
            "subtasks": {
                "WSL2„ÇíÊúâÂäπÂåñ": "Enable WSL2",
                "Docker Desktop„Çí„Ç§„É≥„Çπ„Éà„Éº„É´": "Install Docker Desktop",
                "BuildKit„ÇíÊúâÂäπÂåñ": "Enable BuildKit",
                "Hello World„Ç≥„É≥„ÉÜ„Éä„ÇíÂÆüË°å": "Run Hello World container",
                "Nginx Web„Çµ„Éº„Éê„Éº„ÇíËµ∑Âãï": "Start Nginx Web server"
            },
            "knowledge_items": {
                "Docker„Å®„ÅØÔºü": {
                    "title": "What is Docker?",
                    "content": "# What is Docker?\n\n**Docker** is a platform for containerizing and running applications.\n\n## Docker Features\n\n1. **Environment Consistency**: Works the same in Dev‚ÜíProd environments\n2. **Lightweight**: Faster startup than VMs, resource-efficient\n3. **Portability**: Works the same anywhere\n4. **Scalability**: Easy to scale out\n5. **Isolation**: Run applications independently\n\n## Container vs VM\n\n| Feature | Container | VM |\n|---------|-----------|----|\n| Startup Time | Seconds | Minutes |\n| Size | MB | GB |\n| OS | Shares host OS | Independent OS |\n| Overhead | Low | High |\n\n## Docker Use Cases\n\n- Microservices architecture\n- CI/CD pipelines\n- Unified development environments\n- Cloud-native applications"
                },
                "WSL2 + Docker DesktopÁí∞Â¢ÉÊßãÁØâ": {
                    "title": "WSL2 + Docker Desktop Environment Setup",
                    "content": "# WSL2 + Docker Desktop Environment Setup\n\n## 1. Enable WSL2\n\nRun in PowerShell (as Administrator):\n```powershell\nwsl --install\n```\n\n## 2. Install Docker Desktop\n\n- Download from Docker official website\n- Settings ‚Üí General ‚Üí Check \"Use WSL 2 based engine\"\n\n## 3. Enable BuildKit\n\nAdd the following in Settings ‚Üí Docker Engine:\n```json\n{\n  \"features\": {\n    \"buildkit\": true\n  }\n}\n```\n\nOr set via environment variable:\n```bash\nexport DOCKER_BUILDKIT=1\n```\n\n## 4. Project Placement\n\nPlace in WSL filesystem (fast I/O):\n```bash\n/home/<username>/projects/...\n```\n\nAvoid Windows filesystem (slow):\n```bash\n/mnt/c/Users/...\n```\n\n## 5. Create .dockerignore File\n\n```\nnode_modules\n.git\n.env\nDockerfile*\ndocker-compose*.yml\nlogs\ndist\ncoverage\n**/__pycache__\n**/.pytest_cache\n```"
                },
                "Hello WorldÂÆüË°å": {
                    "title": "Hello World Execution",
                    "content": "# Hello World Container Execution\ndocker run hello-world\n\n# List images\ndocker images\n\n# List running containers\ndocker ps\n\n# List all containers (including stopped)\ndocker ps -a\n\n# Remove container\ndocker rm <container_id>\n\n# Remove image\ndocker rmi hello-world"
                },
                "Nginx Web„Çµ„Éº„Éê„Éº„ÅÆËµ∑Âãï": {
                    "title": "Start Nginx Web Server",
                    "content": "# Start Nginx container in background\ndocker run -d -p 8080:80 --name my-nginx nginx\n\n# Access http://localhost:8080 in browser\n\n# Check logs\ndocker logs my-nginx\n\n# Show logs in real-time\ndocker logs -f my-nginx\n\n# Stop container\ndocker stop my-nginx\n\n# Restart container\ndocker restart my-nginx\n\n# Remove container (after stopping)\ndocker rm my-nginx"
                },
                "ÊºîÁøíÔºöÂàù„ÇÅ„Å¶„ÅÆDocker„Ç≥„É≥„ÉÜ„Éä": {
                    "title": "Exercise: First Docker Container",
                    "content": "# Exercise: First Docker Container\n\n## Goal\nStart multiple containers and master basic operations\n\n## Steps\n\n### 1. Interactive Shell with Ubuntu Container\n```bash\ndocker run -it ubuntu bash\n\n# Inside container\napt-get update\napt-get install -y curl\ncurl https://example.com\nexit\n```\n\n### 2. Run Script with Python Container\n```bash\necho 'print(\"Hello Docker\")' > hello.py\ndocker run -v $(pwd):/app python:3.11 python /app/hello.py\n```\n\n### 3. Start MySQL Container\n```bash\ndocker run -d \\\n  --name mysql \\\n  -e MYSQL_ROOT_PASSWORD=password \\\n  -e MYSQL_DATABASE=testdb \\\n  -p 3306:3306 \\\n  mysql:8.0\n\n# Connection test\ndocker exec -it mysql mysql -u root -ppassword\n```\n\n### 4. Container Cleanup\n```bash\n# Stop all containers\ndocker stop $(docker ps -aq)\n\n# Remove all containers\ndocker rm $(docker ps -aq)\n\n# Remove unused images\ndocker image prune -a\n```\n\n## Checkpoints\n- [ ] Executed commands inside container\n- [ ] Shared files via volume mount\n- [ ] Network communication between containers\n- [ ] Understood cleanup methods"
                },
                "„Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞Ôºö„Çà„Åè„ÅÇ„ÇãÂïèÈ°å": {
                    "title": "Troubleshooting: Common Issues",
                    "content": "# Troubleshooting: Common Issues\n\n## Issue 1: Port Already in Use\n\n**Error:**\n```\nError: bind: address already in use\n```\n\n**Solution:**\n```bash\n# Check port in use (Windows)\nnetstat -ano | findstr :8080\n\n# Check port in use (Linux/Mac)\nlsof -i :8080\n\n# Use different port\ndocker run -p 8081:80 nginx\n```\n\n## Issue 2: Slow Image Pull\n\n**Solution:**\n```json\n// Docker Desktop > Settings > Docker Engine\n{\n  \"registry-mirrors\": [\n    \"https://mirror.gcr.io\"\n  ]\n}\n```\n\n## Issue 3: WSL2 Disk Space Insufficient\n\n**Check:**\n```bash\ndocker system df\n```\n\n**Solution:**\n```bash\n# Remove unused resources\ndocker system prune -a --volumes\n\n# WSL2 disk compression (PowerShell)\nwsl --shutdown\noptimize-vhd -Path $env:LOCALAPPDATA\\Packages\\CanonicalGroupLimited*\\LocalState\\ext4.vhdx -Mode Full\n```\n\n## Issue 4: Container Won't Start\n\n**Diagnosis:**\n```bash\n# Check logs\ndocker logs <container_name>\n\n# Check details\ndocker inspect <container_name>\n\n# Check events\ndocker events --since 30m\n```\n\n## Issue 5: Permission Denied\n\n**Cause:** File access with non-root user\n\n**Solution:**\n```dockerfile\n# Set permissions in Dockerfile\nRUN chown -R app:app /app\nUSER app\n```"
                }
            }
        },
        "Á¨¨2ÈÄ±ÔºöDockerfile‰ΩúÊàê„Å®Âü∫Êú¨„Ç≥„Éû„É≥„Éâ": {
            "title": "Week 2: Dockerfile Creation and Basic Commands",
            "description": "Create Dockerfile, build images, basic Docker commands",
            "subtasks": {
                "Node.js Dockerfile„Çí‰ΩúÊàê": "Create Node.js Dockerfile",
                "„Ç§„É°„Éº„Ç∏„Çí„Éì„É´„Éâ": "Build image",
                "Non-root„É¶„Éº„Ç∂„Éº„ÅßÂÆüË°å": "Run as non-root user",
                "Âü∫Êú¨„Ç≥„Éû„É≥„Éâ„ÇíÁ∑¥Áøí": "Practice basic commands"
            },
            "knowledge_items": {
                "Node.js DockerfileÔºàNon-root + AlpineÔºâ": {
                    "title": "Node.js Dockerfile (Non-root + Alpine)",
                    "content": "# Dockerfile\nFROM node:20-alpine\n\n# Set working directory\nWORKDIR /app\n\n# Copy package.json\nCOPY package*.json ./\n\n# Install production dependencies only\nRUN npm ci --omit=dev\n\n# Copy source code\nCOPY . .\n\n# Create non-root user\nRUN addgroup -g 1001 -S nodejs && adduser -S app -u 1001\n\n# Switch user\nUSER app\n\n# Expose port\nEXPOSE 3000\n\n# Start application\nCMD [\"npm\", \"start\"]"
                },
                "package.json„Å®server.js": {
                    "title": "package.json and server.js",
                    "content": "// package.json\n{\n  \"name\": \"docker-app\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"start\": \"node server.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.19.2\"\n  }\n}\n\n// server.js\nconst express = require('express');\nconst app = express();\n\napp.get('/', (req, res) => {\n  res.send('Hello from Docker!');\n});\n\napp.get('/health', (req, res) => {\n  res.status(200).json({ status: 'OK' });\n});\n\napp.listen(3000, () => {\n  console.log('Server running on port 3000');\n});"
                },
                "„Ç§„É°„Éº„Ç∏„ÅÆ„Éì„É´„Éâ„Å®ÂÆüË°å": {
                    "title": "Build and Run Image",
                    "content": "# Build image\ndocker build -t my-node-app .\n\n# Start container\ndocker run -d -p 3000:3000 --name app my-node-app\n\n# Access http://localhost:3000 in browser\n\n# Execute command inside container\ndocker exec -it app sh\n\n# Check logs\ndocker logs -f app\n\n# Container details\ndocker inspect app\n\n# Resource usage\ndocker stats app"
                },
                "DockerÂü∫Êú¨„Ç≥„Éû„É≥„Éâ‰∏ÄË¶ß": {
                    "title": "Docker Basic Commands Reference",
                    "content": "# Docker Basic Commands Reference\n\n## Image Operations\n\n```bash\n# List images\ndocker images\n\n# Build image\ndocker build -t <name>:<tag> .\n\n# Remove image\ndocker rmi <image_id>\n\n# Remove unused images\ndocker image prune\n```\n\n## Container Operations\n\n```bash\n# Start container\ndocker run -d -p 8080:80 --name <name> <image>\n\n# List containers\ndocker ps        # Running\ndocker ps -a     # All\n\n# Stop container\ndocker stop <container>\n\n# Remove container\ndocker rm <container>\n\n# Execute command inside container\ndocker exec -it <container> sh\n```\n\n## Logs and Debugging\n\n```bash\n# Show logs\ndocker logs <container>\ndocker logs -f <container>  # Real-time\n\n# Container details\ndocker inspect <container>\n\n# Resource usage\ndocker stats\n```\n\n## Cleanup\n\n```bash\n# Remove all\ndocker system prune -a\n\n# Remove including volumes\ndocker system prune -a --volumes\n```"
                },
                "DockerfileÊúÄÈÅ©Âåñ„ÉÜ„ÇØ„Éã„ÉÉ„ÇØ": {
                    "title": "Dockerfile Optimization Techniques",
                    "content": "# Dockerfile Optimization Techniques\n\n# 1. Leverage layer cache\n# Put less frequently changed items first\nFROM node:20-alpine\nWORKDIR /app\n\n# Copy dependencies first (cache utilization)\nCOPY package*.json ./\nRUN npm ci --omit=dev\n\n# Copy source code later\nCOPY . .\n\n# 2. Combine multiple RUN commands (reduce layers)\n# Bad example\nRUN apt-get update\nRUN apt-get install -y curl\nRUN apt-get clean\n\n# Good example\nRUN apt-get update && \\\n    apt-get install -y curl && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# 3. Multi-stage for size reduction\nFROM node:20 AS builder\nWORKDIR /app\nCOPY . .\nRUN npm install && npm run build\n\nFROM node:20-alpine\nCOPY --from=builder /app/dist ./dist\nCMD [\"node\", \"dist/server.js\"]\n\n# 4. Use .dockerignore\n# .dockerignore\nnode_modules\n.git\n.env\n*.log\nREADME.md"
                },
                "ÊºîÁøíÔºöFull-stack Dockerfile„Çí‰ΩúÊàê": {
                    "title": "Exercise: Create Full-stack Dockerfile",
                    "content": "# Exercise: Create Full-stack Dockerfile\n\n## Goal\nDockerize React + Node.js full-stack application\n\n## React Dockerfile\n```dockerfile\n# frontend/Dockerfile\nFROM node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\nFROM nginx:alpine\nCOPY --from=builder /app/build /usr/share/nginx/html\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n```\n\n## Node.js API Dockerfile\n```dockerfile\n# backend/Dockerfile\nFROM node:20-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --omit=dev && \\\n    apk add --no-cache curl\n\nCOPY . .\n\nRUN addgroup -g 1001 -S nodejs && \\\n    adduser -S api -u 1001 && \\\n    chown -R api:nodejs /app\n\nUSER api\nEXPOSE 3000\n\nHEALTHCHECK --interval=30s --timeout=3s \\\n  CMD curl -f http://localhost:3000/health || exit 1\n\nCMD [\"npm\", \"start\"]\n```\n\n## nginx.conf\n```nginx\nserver {\n    listen 80;\n    location / {\n        root /usr/share/nginx/html;\n        try_files $uri /index.html;\n    }\n    location /api/ {\n        proxy_pass http://backend:3000/;\n    }\n}\n```\n\n## Test\n```bash\n# Build Frontend\ncd frontend\ndocker build -t my-frontend .\n\n# Build Backend\ncd backend\ndocker build -t my-backend .\n\n# Start\ndocker run -d --name api my-backend\ndocker run -d --name web -p 80:80 my-frontend\n```"
                },
                "Docker„Ç≥„Éû„É≥„Éâ„ÉÅ„Éº„Éà„Ç∑„Éº„Éà": {
                    "title": "Docker Command Cheat Sheet",
                    "content": "# Docker Command Cheat Sheet\n\n## Image Management\n```bash\n# Build\ndocker build -t name:tag .\ndocker build --no-cache -t name:tag .  # No cache\n\n# List\ndocker images\ndocker images -a  # Include intermediate images\n\n# Remove\ndocker rmi <image_id>\ndocker rmi $(docker images -q)  # Remove all\n\n# Tag\ndocker tag source:tag target:tag\n\n# Push/Pull\ndocker push name:tag\ndocker pull name:tag\n\n# Search\ndocker search nginx\n\n# History\ndocker history <image>\n```\n\n## Container Management\n```bash\n# Start\ndocker run -d -p 8080:80 --name web nginx\ndocker run -it ubuntu bash  # Interactive mode\ndocker run --rm alpine echo \"Hello\"  # Remove after execution\n\n# List\ndocker ps\ndocker ps -a\ndocker ps -q  # IDs only\n\n# Control\ndocker start <container>\ndocker stop <container>\ndocker restart <container>\ndocker pause <container>\ndocker unpause <container>\n\n# Remove\ndocker rm <container>\ndocker rm $(docker ps -aq)  # Remove all\ndocker rm -f $(docker ps -aq)  # Force remove\n\n# Execute\ndocker exec -it <container> bash\ndocker exec <container> ls /app\n\n# Logs\ndocker logs <container>\ndocker logs -f <container>  # Follow\ndocker logs --tail 100 <container>  # Last 100 lines\n\n# Information\ndocker inspect <container>\ndocker stats\ndocker top <container>\n\n# Copy\ndocker cp <container>:/path ./local\ndocker cp ./local <container>:/path\n```\n\n## System Management\n```bash\n# Information\ndocker info\ndocker version\ndocker system df  # Disk usage\n\n# Cleanup\ndocker system prune  # Remove unused\ndocker system prune -a  # Remove all\ndocker system prune -a --volumes  # Include volumes\n\n# Volumes\ndocker volume ls\ndocker volume create <name>\ndocker volume rm <name>\ndocker volume prune\n\n# Networks\ndocker network ls\ndocker network create <name>\ndocker network rm <name>\ndocker network inspect <name>\n```"
                }
            }
        },
        "Á¨¨3ÈÄ±ÔºöVolumes & Networks": {
            "title": "Week 3: Volumes & Networks",
            "description": "Data persistence with volumes, container networking",
            "subtasks": {
                "Named Volumes„Çí‰Ωø„ÅÜ": "Use Named Volumes",
                "Bind Mounts„Çí‰Ωø„ÅÜ": "Use Bind Mounts",
                "Custom Network„Çí‰ΩúÊàê": "Create Custom Network"
            },
            "knowledge_items": {
                "Volumes vs Bind Mounts": {
                    "title": "Volumes vs Bind Mounts",
                    "content": "# Volumes vs Bind Mounts\n\n## Named Volumes (Recommended)\n\n**Features:**\n- Managed by Docker\n- High portability\n- Easy backup\n- Production-ready\n\n**Usage:**\n```bash\ndocker run -v mydata:/data postgres\n```\n\n## Bind Mounts\n\n**Features:**\n- Direct mount of host path\n- Convenient for development (hot reload)\n- Note path specification on Windows/WSL2\n\n**Usage:**\n```bash\n# PowerShell\ndocker run -v ${PWD}:/app node\n\n# Git Bash/WSL\ndocker run -v $(pwd):/app node\n\n# cmd\ndocker run -v %cd%:/app node\n```\n\n## When to Use Which?\n\n| Use Case | Recommended |\n|----------|-------------|\n| Database | Named Volumes |\n| Development (hot reload) | Bind Mounts |\n| Production | Named Volumes |\n| Config files | Bind Mounts |"
                },
                "PostgreSQL with Volume": {
                    "title": "PostgreSQL with Volume",
                    "content": "# Create Named Volume\ndocker volume create pg_data\n\n# Start PostgreSQL container\ndocker run -d \\\n  --name postgres \\\n  -e POSTGRES_PASSWORD=password \\\n  -e POSTGRES_DB=mydb \\\n  -v pg_data:/var/lib/postgresql/data \\\n  -p 5432:5432 \\\n  postgres:13\n\n# Verify data persistence\ndocker exec -it postgres psql -U postgres -d mydb\n\n# Data remains even after container removal\ndocker rm -f postgres\n\n# Restart with same Volume to restore data\ndocker run -d \\\n  --name postgres \\\n  -e POSTGRES_PASSWORD=password \\\n  -v pg_data:/var/lib/postgresql/data \\\n  postgres:13"
                },
                "Docker Networks": {
                    "title": "Docker Networks",
                    "content": "# Docker Networks\n\n## Network Types\n\n1. **bridge** (default): Container communication within same host\n2. **host**: Directly use host network\n3. **none**: Network disabled\n4. **custom bridge**: Custom network (recommended)\n\n## Custom Network Benefits\n\n- **DNS Resolution**: Communicate using container names\n- **Isolation**: Separate networks for better security\n- **Flexibility**: Connect only necessary containers\n\n## Usage Example\n\n```bash\n# Create custom network\ndocker network create mynet\n\n# Start containers connected to network\ndocker run -d --name web --network mynet nginx\ndocker run -d --name db --network mynet postgres\n\n# web can ping db (DNS resolution)\ndocker exec -it web ping db\n```"
                },
                "Custom NetworkÂÆüË∑µ": {
                    "title": "Custom Network Practice",
                    "content": "# Create network\ndocker network create app-network\n\n# Start PostgreSQL\ndocker run -d \\\n  --name db \\\n  --network app-network \\\n  -e POSTGRES_PASSWORD=password \\\n  postgres:13\n\n# Start Node.js app (connect to db)\ndocker run -d \\\n  --name web \\\n  --network app-network \\\n  -p 3000:3000 \\\n  -e DB_HOST=db \\\n  -e DB_USER=postgres \\\n  -e DB_PASSWORD=password \\\n  my-node-app\n\n# Check network information\ndocker network inspect app-network\n\n# Test communication between containers\ndocker exec -it web ping db"
                },
                "ÊºîÁøíÔºöWordPress + MySQLÊßãÊàê": {
                    "title": "Exercise: WordPress + MySQL Setup",
                    "content": "# Exercise: WordPress + MySQL Setup\n\n## Goal\nBuild WordPress environment using custom network and Volumes\n\n## Steps\n\n### 1. Create Network and Volumes\n```bash\ndocker network create wordpress-net\ndocker volume create wp_data\ndocker volume create db_data\n```\n\n### 2. Start MySQL Container\n```bash\ndocker run -d \\\n  --name wp-mysql \\\n  --network wordpress-net \\\n  -e MYSQL_ROOT_PASSWORD=rootpass \\\n  -e MYSQL_DATABASE=wordpress \\\n  -e MYSQL_USER=wpuser \\\n  -e MYSQL_PASSWORD=wppass \\\n  -v db_data:/var/lib/mysql \\\n  mysql:8.0\n```\n\n### 3. Start WordPress Container\n```bash\ndocker run -d \\\n  --name wordpress \\\n  --network wordpress-net \\\n  -p 8080:80 \\\n  -e WORDPRESS_DB_HOST=wp-mysql \\\n  -e WORDPRESS_DB_USER=wpuser \\\n  -e WORDPRESS_DB_PASSWORD=wppass \\\n  -e WORDPRESS_DB_NAME=wordpress \\\n  -v wp_data:/var/www/html \\\n  wordpress:latest\n```\n\n### 4. Connection Test\n```bash\n# Connect from WordPress container to MySQL\ndocker exec -it wordpress bash\nping wp-mysql\nexit\n\n# Access http://localhost:8080 in browser\n```\n\n### 5. Backup and Restore\n```bash\n# Backup\ndocker exec wp-mysql mysqldump -u wpuser -pwppass wordpress > backup.sql\n\n# Restore\ndocker exec -i wp-mysql mysql -u wpuser -pwppass wordpress < backup.sql\n```\n\n## Checkpoints\n- [ ] Communication via custom network\n- [ ] Data persisted with Volume\n- [ ] Data remains after container removal\n- [ ] Backup/restore successful"
                },
                "„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉÅ„É•„Éº„Éã„É≥„Ç∞": {
                    "title": "Performance Tuning",
                    "content": "# Docker Performance Tuning\n\n## 1. I/O Optimization on WSL2\n\n### Place project in WSL filesystem\n```bash\n# Fast (recommended)\n/home/username/projects/myapp\n\n# Slow (avoid)\n/mnt/c/Users/username/projects/myapp\n```\n\n### Performance Measurement\n```bash\n# WSL filesystem\ntime docker run -v $HOME/project:/app node npm install\n# ‚Üí 30 seconds\n\n# Windows filesystem  \ntime docker run -v /mnt/c/project:/app node npm install\n# ‚Üí 5 minutes\n```\n\n## 2. BuildKit Utilization\n\n```bash\n# Enable BuildKit\nexport DOCKER_BUILDKIT=1\n\n# Cache mount (dependency cache)\nRUN --mount=type=cache,target=/root/.npm \\\n    npm install\n\n# Parallel build\ndocker buildx build \\\n  --platform linux/amd64,linux/arm64 \\\n  -t myimage .\n```\n\n## 3. Image Layer Optimization\n\n```dockerfile\n# Bad example (12 layers)\nRUN apt-get update\nRUN apt-get install -y curl\nRUN apt-get install -y git\nRUN apt-get clean\n\n# Good example (1 layer)\nRUN apt-get update && \\\n    apt-get install -y curl git && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n```\n\n## 4. Memory/CPU Limits\n\n```bash\n# Memory limit\ndocker run --memory=\"512m\" --memory-swap=\"1g\" myapp\n\n# CPU limit\ndocker run --cpus=\"1.5\" myapp\n\n# Compose configuration\nservices:\n  web:\n    deploy:\n      resources:\n        limits:\n          cpus: '1.5'\n          memory: 512M\n```\n\n## 5. Log Rotation\n\n```json\n// daemon.json\n{\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  }\n}\n```"
                }
            }
        },
        "Á¨¨4ÈÄ±ÔºöDocker Compose": {
            "title": "Week 4: Docker Compose",
            "description": "Multi-container application management with Docker Compose",
            "subtasks": {
                "compose.yml„Çí‰ΩúÊàê": "Create compose.yml",
                "2-tierÊßãÊàê„ÇíÊßãÁØâ": "Build 2-tier architecture",
                "Networks„ÇíÂàÜÈõ¢": "Separate Networks"
            },
            "knowledge_items": {
                "Docker Compose v2„ÅÆÁâπÂæ¥": {
                    "title": "Docker Compose v2 Features",
                    "content": "# Docker Compose v2 Features\n\n## Compose v2 Changes\n\n- **Command**: `docker compose` (no hyphen)\n- **No version needed**: `version:` field not required\n- **BuildKit integration**: BuildKit used by default\n- **profiles**: Service grouping\n\n## Basic Commands\n\n```bash\n# Start\ndocker compose up -d\n\n# Stop and remove\ndocker compose down\n\n# Show logs\ndocker compose logs -f\n\n# List services\ndocker compose ps\n\n# Rebuild\ndocker compose build\n\n# Start specific service only\ndocker compose up -d web\n\n# Start with profile\ndocker compose --profile monitoring up -d\n```"
                },
                "compose.ymlÔºà2-tierÊßãÊàêÔºâ": {
                    "title": "compose.yml (2-tier Architecture)",
                    "content": "# compose.yml\nname: my-app\n\nnetworks:\n  frontend:\n  backend:\n\nservices:\n  web:\n    build: .\n    ports:\n      - \"3000:3000\"\n    environment:\n      - DB_HOST=db\n      - DB_USER=postgres\n      - DB_PASSWORD=password\n      - DB_NAME=mydb\n    depends_on:\n      - db\n    networks:\n      - frontend\n      - backend\n    restart: unless-stopped\n\n  db:\n    image: postgres:13\n    environment:\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=mydb\n    volumes:\n      - pg_data:/var/lib/postgresql/data\n    networks:\n      - backend\n    restart: unless-stopped\n\nvolumes:\n  pg_data:"
                },
                "Áí∞Â¢ÉÂ§âÊï∞„Éï„Ç°„Ç§„É´Ôºà.envÔºâ": {
                    "title": "Environment Variables File (.env)",
                    "content": "# .env\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=password\nPOSTGRES_DB=mydb\nNODE_ENV=development\n\n# compose.yml (using environment variables)\nservices:\n  db:\n    image: postgres:13\n    env_file: .env\n    # Or specify individually\n    environment:\n      - POSTGRES_USER=${POSTGRES_USER}\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\n      - POSTGRES_DB=${POSTGRES_DB}"
                },
                "Profiles‰ΩøÁî®‰æã": {
                    "title": "Profiles Usage Example",
                    "content": "# compose.yml\nservices:\n  web:\n    build: .\n    ports: [\"3000:3000\"]\n\n  db:\n    image: postgres:13\n\n  # Monitoring services (optional)\n  prometheus:\n    image: prom/prometheus\n    ports: [\"9090:9090\"]\n    profiles: [monitoring]\n\n  grafana:\n    image: grafana/grafana\n    ports: [\"3001:3000\"]\n    profiles: [monitoring]\n\n# Start basic services only\ndocker compose up -d\n\n# Start including monitoring\ndocker compose --profile monitoring up -d"
                },
                "ÊºîÁøíÔºöMERN Stack with Compose": {
                    "title": "Exercise: MERN Stack with Compose",
                    "content": "# Exercise: MERN Stack with Compose\n\n## Goal\nBuild MongoDB + Express + React + Node.js with Docker Compose\n\n## compose.yml\n```yaml\nname: mern-stack\n\nnetworks:\n  frontend:\n  backend:\n\nservices:\n  # React Frontend\n  client:\n    build:\n      context: ./client\n      dockerfile: Dockerfile\n    ports:\n      - \"3000:3000\"\n    environment:\n      - REACT_APP_API_URL=http://localhost:5000\n    networks:\n      - frontend\n    depends_on:\n      - api\n    volumes:\n      - ./client:/app\n      - /app/node_modules\n\n  # Express API\n  api:\n    build: ./server\n    ports:\n      - \"5000:5000\"\n    environment:\n      - MONGO_URI=mongodb://mongo:27017/merndb\n      - NODE_ENV=development\n    networks:\n      - frontend\n      - backend\n    depends_on:\n      mongo:\n        condition: service_healthy\n    volumes:\n      - ./server:/app\n      - /app/node_modules\n\n  # MongoDB\n  mongo:\n    image: mongo:7\n    ports:\n      - \"27017:27017\"\n    environment:\n      - MONGO_INITDB_DATABASE=merndb\n    volumes:\n      - mongo_data:/data/db\n    networks:\n      - backend\n    healthcheck:\n      test: echo 'db.runCommand(\"ping\").ok' | mongosh localhost:27017/test --quiet\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  # Mongo Express (optional)\n  mongo-express:\n    image: mongo-express\n    ports:\n      - \"8081:8081\"\n    environment:\n      - ME_CONFIG_MONGODB_URL=mongodb://mongo:27017/\n    networks:\n      - backend\n    depends_on:\n      - mongo\n    profiles:\n      - tools\n\nvolumes:\n  mongo_data:\n```\n\n## Start\n```bash\n# Basic services only\ndocker compose up -d\n\n# Start Mongo Express too\ndocker compose --profile tools up -d\n\n# Show logs\ndocker compose logs -f api\n\n# Stop and remove\ndocker compose down\n\n# Remove including volumes\ndocker compose down -v\n```"
                },
                "Compose „Éà„É©„Éñ„É´„Ç∑„É•„Éº„ÉÜ„Ç£„É≥„Ç∞": {
                    "title": "Compose Troubleshooting",
                    "content": "# Compose Troubleshooting\n\n## Issue 1: Service Won't Start\n\n```bash\n# Check logs\ndocker compose logs <service>\n\n# Check events\ndocker compose events\n\n# Validate configuration\ndocker compose config\n```\n\n## Issue 2: depends_on Not Working\n\n```yaml\n# Bad example (startup order only)\nservices:\n  web:\n    depends_on:\n      - db\n\n# Good example (wait for health check)\nservices:\n  web:\n    depends_on:\n      db:\n        condition: service_healthy\n  db:\n    healthcheck:\n      test: [\"CMD\", \"pg_isready\"]\n```\n\n## Issue 3: Environment Variables Not Loaded\n\n```yaml\n# Explicitly specify .env file\nservices:\n  web:\n    env_file:\n      - .env\n      - .env.local\n```\n\n## Issue 4: Volume Not Updating\n\n```bash\n# Recreate volumes\ndocker compose down -v\ndocker compose up -d\n\n# Or remove specific volume\ndocker volume rm <project>_<volume_name>\n```\n\n## Issue 5: Network Error\n\n```bash\n# Reset network\ndocker compose down\ndocker network prune\ndocker compose up -d\n```\n\n## Debug Commands\n\n```bash\n# Check service status\ndocker compose ps\n\n# Resource usage\ndocker compose top\n\n# Restart specific service\ndocker compose restart web\n\n# Scale service\ndocker compose up -d --scale web=3\n\n# Show configuration (after variable expansion)\ndocker compose config\n```"
                },
                "Docker Compose „Éô„Çπ„Éà„Éó„É©„ÇØ„ÉÜ„Ç£„Çπ": {
                    "title": "Docker Compose Best Practices",
                    "content": "# Docker Compose Best Practices\n\n## 1. Separate Files by Environment\n\n```bash\n# Structure\ncompose.yml           # Common settings\ncompose.dev.yml      # Development environment\ncompose.prod.yml     # Production environment\n\n# Start development environment\ndocker compose -f compose.yml -f compose.dev.yml up -d\n\n# Start production environment\ndocker compose -f compose.yml -f compose.prod.yml up -d\n```\n\n## 2. Implement Health Checks\n\n```yaml\nservices:\n  api:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 3s\n      retries: 3\n      start_period: 40s\n```\n\n## 3. Resource Limits\n\n```yaml\nservices:\n  web:\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n```\n\n## 4. Log Management\n\n```yaml\nservices:\n  web:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n```\n\n## 5. Security\n\n```yaml\nservices:\n  web:\n    # Read-only filesystem\n    read_only: true\n    tmpfs:\n      - /tmp\n    # Capability restrictions\n    cap_drop:\n      - ALL\n    cap_add:\n      - NET_BIND_SERVICE\n    # Seccomp profile\n    security_opt:\n      - no-new-privileges:true\n```\n\n## 6. Secrets Management\n\n```yaml\nservices:\n  db:\n    secrets:\n      - db_password\n\nsecrets:\n  db_password:\n    file: ./secrets/db_password.txt\n```"
                }
            }
        },
        "Á¨¨5ÈÄ±ÔºöMulti-stage Build & Healthcheck": {
            "title": "Week 5: Multi-stage Build & Healthcheck",
            "description": "Optimize images with multi-stage builds, implement healthchecks",
            "subtasks": {
                "Multi-stage Build„Çí‰ΩúÊàê": "Create Multi-stage Build",
                "Healthcheck„ÇíËøΩÂä†": "Add Healthcheck",
                "„Ç§„É°„Éº„Ç∏„Çµ„Ç§„Ç∫„ÇíÊØîËºÉ": "Compare image sizes"
            },
            "knowledge_items": {
                "Multi-stage Dockerfile": {
                    "title": "Multi-stage Dockerfile",
                    "content": "# Multi-stage Dockerfile\n# Build stage\nFROM node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\n# Runtime stage\nFROM node:20-alpine\nWORKDIR /app\n\n# Copy only necessary files from build stage\nCOPY --from=builder /app/dist ./dist\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY package*.json ./\n\n# Create non-root user\nRUN addgroup -g 1001 -S nodejs && adduser -S app -u 1001 \\\n    && apk add --no-cache curl\n\nUSER app\nEXPOSE 3000\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD curl -fsS http://localhost:3000/health || exit 1\n\nCMD [\"node\", \"dist/server.js\"]"
                },
                "Multi-stage Build„ÅÆÂà©ÁÇπ": {
                    "title": "Multi-stage Build Benefits",
                    "content": "# Multi-stage Build Benefits\n\n## Advantages\n\n1. **Image Size Reduction**\n   - Don't include build tools in final image\n   - Exclude unnecessary files for production\n\n2. **Security Improvement**\n   - Reduce attack surface\n   - Don't leave build-time secrets\n\n3. **Build Efficiency**\n   - Leverage layer cache\n   - Enable parallel builds\n\n## Size Comparison Example\n\n| Method | Size |\n|--------|------|\n| Single-stage | 500MB |\n| Multi-stage | 150MB |\n\n## Best Practices\n\n```dockerfile\n# 1. Use Alpine base image\nFROM node:20-alpine\n\n# 2. Copy dependencies first (cache utilization)\nCOPY package*.json ./\nRUN npm ci\n\n# 3. Copy source code later\nCOPY . .\n\n# 4. Exclude unnecessary files with .dockerignore\n```"
                },
                "HealthcheckÂÆüË£Ö": {
                    "title": "Healthcheck Implementation",
                    "content": "# Define Healthcheck in Dockerfile\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD curl -fsS http://localhost:3000/health || exit 1\n\n# Define in Compose\nservices:\n  web:\n    build: .\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 3s\n      retries: 3\n      start_period: 5s\n\n# Implement health endpoint in Node.js\napp.get('/health', (req, res) => {\n  res.status(200).json({ \n    status: 'OK',\n    uptime: process.uptime(),\n    timestamp: Date.now()\n  });\n});"
                },
                "ÊºîÁøíÔºö„Ç§„É°„Éº„Ç∏„Çµ„Ç§„Ç∫ÊúÄÈÅ©Âåñ„Ç≥„É≥„ÉÜ„Çπ„Éà": {
                    "title": "Exercise: Image Size Optimization Contest",
                    "content": "# Exercise: Image Size Optimization Contest\n\n## Goal\nCompare different methods with same app and create smallest image\n\n## Baseline (No Optimization)\n```dockerfile\nFROM node:20\nWORKDIR /app\nCOPY . .\nRUN npm install\nCMD [\"npm\", \"start\"]\n```\nSize: ~1.1GB\n\n## Optimization Level 1: Use Alpine\n```dockerfile\nFROM node:20-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --omit=dev\nCOPY . .\nCMD [\"npm\", \"start\"]\n```\nSize: ~180MB (-92%)\n\n## Optimization Level 2: Multi-stage\n```dockerfile\nFROM node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build && npm prune --production\n\nFROM node:20-alpine\nWORKDIR /app\nCOPY --from=builder /app/dist ./dist\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY package*.json ./\nCMD [\"node\", \"dist/server.js\"]\n```\nSize: ~120MB (-89%)\n\n## Optimization Level 3: Distroless\n```dockerfile\nFROM node:20-alpine AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\nFROM gcr.io/distroless/nodejs20-debian11\nWORKDIR /app\nCOPY --from=builder /app/dist ./dist\nCOPY --from=builder /app/node_modules ./node_modules\nCMD [\"dist/server.js\"]\n```\nSize: ~80MB (-93%)\n\n## Comparison Results\n```bash\n# Check size\ndocker images | grep myapp\n\n# Measure startup time\ntime docker run --rm myapp\n```\n\n## Challenge\n- [ ] Achieve under 50MB\n- [ ] 0 CRITICAL in security scan\n- [ ] Startup time under 3 seconds"
                }
            }
        },
        "Á¨¨6ÈÄ±ÔºöPrivate Registry & „Çª„Ç≠„É•„É™„ÉÜ„Ç£": {
            "title": "Week 6: Private Registry & Security",
            "description": "Set up private registry, security scanning, best practices",
            "subtasks": {
                "Private Registry„ÇíÊßãÁØâ": "Build Private Registry",
                "Trivy„Åß„Çπ„Ç≠„É£„É≥": "Scan with Trivy",
                "Non-root„É¶„Éº„Ç∂„Éº„ÅßÂÆüË°å": "Run as non-root user"
            },
            "knowledge_items": {
                "Private RegistryÊßãÁØâ": {
                    "title": "Private Registry Setup",
                    "content": "# Start Registry container\ndocker run -d \\\n  -p 5000:5000 \\\n  --name registry \\\n  -v registry_data:/var/lib/registry \\\n  registry:2\n\n# Tag image\ndocker tag my-app localhost:5000/my-app:latest\n\n# Push to registry\ndocker push localhost:5000/my-app:latest\n\n# Pull from registry\ndocker pull localhost:5000/my-app:latest\n\n# List images in registry\ncurl http://localhost:5000/v2/_catalog"
                },
                "Trivy„Åß„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Çπ„Ç≠„É£„É≥": {
                    "title": "Security Scanning with Trivy",
                    "content": "# Install Trivy (WSL2/Linux)\ncurl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin\n\n# Scan image\ntrivy image my-app:latest\n\n# Show high risk only\ntrivy image --severity HIGH,CRITICAL my-app:latest\n\n# Output in JSON format\ntrivy image --format json --output results.json my-app:latest\n\n# Run with Docker\ndocker run --rm \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  aquasec/trivy:latest \\\n  image my-app:latest"
                },
                "„Çª„Ç≠„É•„É™„ÉÜ„Ç£„Éô„Çπ„Éà„Éó„É©„ÇØ„ÉÜ„Ç£„Çπ": {
                    "title": "Security Best Practices",
                    "content": "# Docker Security Best Practices\n\n## 1. Run as Non-root User\n\n```dockerfile\nRUN addgroup -g 1001 -S app && adduser -S app -u 1001\nUSER app\n```\n\n## 2. Minimal Base Image\n\n- Use Alpine Linux (about 5MB)\n- Distroless (provided by Google)\n\n## 3. Multi-stage Build\n\n- Don't include build tools in final image\n\n## 4. Secret Management\n\n```bash\n# Pass via environment variable (development)\ndocker run -e DB_PASSWORD=secret app\n\n# Use Docker Secrets (production)\ndocker secret create db_password password.txt\n```\n\n## 5. Vulnerability Scanning\n\n- Trivy (recommended)\n- Snyk\n- Clair\n\n## 6. Read-only Filesystem\n\n```yaml\nservices:\n  web:\n    read_only: true\n    tmpfs:\n      - /tmp\n```\n\n## 7. Capability Restrictions\n\n```bash\ndocker run --cap-drop=ALL --cap-add=NET_BIND_SERVICE app\n```"
                },
                "„Çª„Ç≠„É•„É™„ÉÜ„Ç£Ëá™ÂãïÂåñ„Çπ„ÇØ„É™„Éó„Éà": {
                    "title": "Security Automation Script",
                    "content": "#!/bin/bash\n# security-scan.sh - Security scanning script for CI/CD\n\nset -e\n\nIMAGE_NAME=${1:-\"myapp:latest\"}\nTHRESHOLD=${2:-\"HIGH\"}\n\necho \"üîç Security Scanning: $IMAGE_NAME\"\necho \"üìä Threshold: $THRESHOLD\"\n\n# 1. Scan image with Trivy\necho \"\\n=== Trivy Scan ===\"\ntrivy image --severity $THRESHOLD,CRITICAL \\\n  --exit-code 1 \\\n  --format table \\\n  $IMAGE_NAME\n\n# 2. Static analysis of dockerfile with Hadolint\necho \"\\n=== Hadolint Check ===\"\nhadolint Dockerfile || true\n\n# 3. Best practices check with Dockle\necho \"\\n=== Dockle Check ===\"\ndocker run --rm \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  goodwithtech/dockle:latest \\\n  --exit-code 1 \\\n  --exit-level warn \\\n  $IMAGE_NAME\n\n# 4. Generate SBOM\necho \"\\n=== Generating SBOM ===\"\nsyft $IMAGE_NAME -o json > sbom.json\n\n# 5. Report results\necho \"\\n‚úÖ Security scan completed!\"\necho \"üìã SBOM saved to: sbom.json\""
                },
                "ÊºîÁøíÔºö„Çª„Ç≠„É•„Ç¢„Å™„Éó„É≠„ÉÄ„ÇØ„Ç∑„Éß„É≥ÊßãÊàê": {
                    "title": "Exercise: Secure Production Setup",
                    "content": "# Exercise: Secure Production Setup\n\n## Goal\nCreate image with all security best practices applied\n\n## Secure Dockerfile\n```dockerfile\n# ============================================\n# Multi-stage Build: Security Hardened\n# ============================================\n\n# Stage 1: Builder\nFROM node:20-alpine AS builder\n\n# Security updates\nRUN apk update && apk upgrade && \\\n    apk add --no-cache dumb-init\n\nWORKDIR /build\n\n# Copy dependencies first (cache utilization)\nCOPY package*.json ./\nRUN npm ci --omit=dev && npm cache clean --force\n\n# Copy source and build\nCOPY . .\nRUN npm run build && \\\n    npm prune --production\n\n# Stage 2: Runtime (Distroless)\nFROM gcr.io/distroless/nodejs20-debian11:nonroot\n\n# Metadata\nLABEL maintainer=\"your@email.com\"\nLABEL version=\"1.0.0\"\nLABEL description=\"Secure production image\"\n\nWORKDIR /app\n\n# Copy only necessary files\nCOPY --from=builder --chown=nonroot:nonroot /build/dist ./dist\nCOPY --from=builder --chown=nonroot:nonroot /build/node_modules ./node_modules\nCOPY --from=builder --chown=nonroot:nonroot /build/package*.json ./\nCOPY --from=builder /usr/bin/dumb-init /usr/bin/\n\n# Non-root user (distroless default)\nUSER nonroot\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \\\n  CMD [\"node\", \"-e\", \"require('http').get('http://localhost:3000/health', (r) => process.exit(r.statusCode === 200 ? 0 : 1))\"]\n\n# Use dumb-init (PID 1 issue countermeasure)\nENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]\nCMD [\"node\", \"dist/server.js\"]\n```\n\n## Secure Compose Configuration\n```yaml\nservices:\n  api:\n    build: .\n    read_only: true  # Read-only filesystem\n    tmpfs:\n      - /tmp\n    cap_drop:\n      - ALL\n    cap_add:\n      - NET_BIND_SERVICE\n    security_opt:\n      - no-new-privileges:true\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 512M\n    healthcheck:\n      test: [\"CMD\", \"node\", \"healthcheck.js\"]\n      interval: 30s\n```\n\n## Security Checklist\n- [ ] Non-root user\n- [ ] Distroless/Alpine base\n- [ ] Read-only filesystem\n- [ ] Capability restrictions\n- [ ] Resource limits\n- [ ] Trivy scan CRITICAL=0\n- [ ] Healthcheck implemented\n- [ ] Secrets management\n- [ ] TLS communication"
                }
            }
        },
        "Á¨¨7ÈÄ±ÔºöOrchestration & Monitoring": {
            "title": "Week 7: Orchestration & Monitoring",
            "description": "Container orchestration, monitoring stack setup",
            "subtasks": {
                "Docker Swarm„ÇíÂàùÊúüÂåñ": "Initialize Docker Swarm",
                "Monitoring stack„ÇíÊßãÁØâ": "Build Monitoring stack"
            },
            "knowledge_items": {
                "Docker SwarmÂü∫Êú¨": {
                    "title": "Docker Swarm Basics",
                    "content": "# Initialize Swarm mode\ndocker swarm init\n\n# Create service\ndocker service create \\\n  --name web \\\n  --replicas 3 \\\n  -p 80:80 \\\n  nginx\n\n# List services\ndocker service ls\n\n# Service details\ndocker service ps web\n\n# Scale service\ndocker service scale web=5\n\n# Update service\ndocker service update --image nginx:alpine web\n\n# Remove service\ndocker service rm web"
                },
                "Monitoring StackÔºàComposeÔºâ": {
                    "title": "Monitoring Stack (Compose)",
                    "content": "# compose.monitoring.yml\nservices:\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:latest\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - /:/rootfs:ro\n      - /var/run:/var/run:rw\n      - /sys:/sys:ro\n      - /var/lib/docker/:/var/lib/docker:ro\n    restart: unless-stopped\n\n  prometheus:\n    image: prom/prometheus\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n      - prometheus_data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n    restart: unless-stopped\n\n  grafana:\n    image: grafana/grafana\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n    volumes:\n      - grafana_data:/var/lib/grafana\n    restart: unless-stopped\n\nvolumes:\n  prometheus_data:\n  grafana_data:"
                },
                "prometheus.ymlË®≠ÂÆö": {
                    "title": "prometheus.yml Configuration",
                    "content": "# prometheus.yml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n\n  - job_name: 'cadvisor'\n    static_configs:\n      - targets: ['cadvisor:8080']\n\n  - job_name: 'node-exporter'\n    static_configs:\n      - targets: ['node-exporter:9100']"
                }
            }
        },
        "Á¨¨8ÈÄ±ÔºöMicroservicesÊßãÊàê": {
            "title": "Week 8: Microservices Architecture",
            "description": "Build microservices architecture with Docker",
            "subtasks": {
                "API Gateway„ÇíÊßãÁØâ": "Build API Gateway",
                "Microservices„Çí‰ΩúÊàê": "Create Microservices"
            },
            "knowledge_items": {
                "Microservices Compose": {
                    "title": "Microservices Compose",
                    "content": "# compose.microservices.yml\nnetworks:\n  frontend:\n  backend:\n\nservices:\n  gateway:\n    build: ./gateway\n    ports:\n      - \"80:80\"\n    networks:\n      - frontend\n      - backend\n    depends_on:\n      - user-service\n      - order-service\n\n  user-service:\n    build: ./user-service\n    networks:\n      - backend\n    environment:\n      - DB_HOST=user-db\n    depends_on:\n      - user-db\n\n  order-service:\n    build: ./order-service\n    networks:\n      - backend\n    environment:\n      - DB_HOST=order-db\n    depends_on:\n      - order-db\n\n  user-db:\n    image: postgres:13\n    networks:\n      - backend\n    environment:\n      - POSTGRES_DB=users\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - user_pg:/var/lib/postgresql/data\n\n  order-db:\n    image: postgres:13\n    networks:\n      - backend\n    environment:\n      - POSTGRES_DB=orders\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - order_pg:/var/lib/postgresql/data\n\nvolumes:\n  user_pg:\n  order_pg:"
                },
                "Nginx GatewayË®≠ÂÆö": {
                    "title": "Nginx Gateway Configuration",
                    "content": "# nginx.conf\nevents {}\n\nhttp {\n    upstream user_service {\n        server user-service:3001;\n    }\n\n    upstream order_service {\n        server order-service:3002;\n    }\n\n    server {\n        listen 80;\n\n        location /api/users/ {\n            proxy_pass http://user_service/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n        }\n\n        location /api/orders/ {\n            proxy_pass http://order_service/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n        }\n\n        location /health {\n            return 200 'OK';\n            add_header Content-Type text/plain;\n        }\n    }\n}"
                }
            }
        },
        "Á¨¨9-12ÈÄ±ÔºöE-commerce Capstone": {
            "title": "Week 9-12: E-commerce Capstone",
            "description": "Full-stack architecture + CI/CD + Monitoring + Security",
            "subtasks": {
                "FrontendÔºàReact + NginxÔºâ": "Frontend (React + Nginx)",
                "BackendÔºàNode/ExpressÔºâ": "Backend (Node/Express)",
                "DB/CacheÔºàPostgres + RedisÔºâ": "DB/Cache (Postgres + Redis)",
                "CI/CDÊßãÁØâ": "Build CI/CD",
                "Monitoring & Logging": "Monitoring & Logging",
                "SecurityÂº∑Âåñ": "Security Hardening"
            },
            "knowledge_items": {
                "GitHub Actions CI/CD": {
                    "title": "GitHub Actions CI/CD",
                    "content": "# .github/workflows/docker.yml\nname: Docker CI/CD\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: docker/setup-buildx-action@v3\n\n      - uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: ghcr.io/${{ github.repository }}:latest\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n      - name: Run Trivy scan\n        run: |\n          docker run --rm \\\n            -v /var/run/docker.sock:/var/run/docker.sock \\\n            aquasec/trivy:latest \\\n            image ghcr.io/${{ github.repository }}:latest"
                },
                "Full Stack compose.yml": {
                    "title": "Full Stack compose.yml",
                    "content": "# compose.yml (Production)\nservices:\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile.prod\n    ports:\n      - \"80:80\"\n    depends_on:\n      - backend\n    restart: unless-stopped\n\n  backend:\n    build: ./backend\n    environment:\n      - DB_HOST=postgres\n      - REDIS_HOST=redis\n    depends_on:\n      postgres:\n        condition: service_healthy\n      redis:\n        condition: service_started\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 3s\n      retries: 3\n    restart: unless-stopped\n\n  postgres:\n    image: postgres:13-alpine\n    environment:\n      - POSTGRES_DB=ecommerce\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - pg_data:/var/lib/postgresql/data\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U user\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n\n  redis:\n    image: redis:7-alpine\n    volumes:\n      - redis_data:/data\n    restart: unless-stopped\n\nvolumes:\n  pg_data:\n  redis_data:"
                },
                "„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÆåÊàê„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà": {
                    "title": "Project Completion Checklist",
                    "content": "# Project Completion Checklist\n\n## Dockerfile\n- [ ] Use multi-stage build\n- [ ] Run as non-root user\n- [ ] Define healthcheck\n- [ ] Create .dockerignore\n\n## Compose\n- [ ] Separate with networks\n- [ ] Persist with volumes\n- [ ] Manage environment variables with .env\n- [ ] depends_on + healthcheck\n\n## Security\n- [ ] Run Trivy scan\n- [ ] Fix vulnerabilities\n- [ ] Environment variable secrets\n- [ ] Read-only filesystem (where possible)\n\n## CI/CD\n- [ ] GitHub Actions setup\n- [ ] Automatic build & push\n- [ ] Automatic tests\n- [ ] Automatic scanning\n\n## Monitoring\n- [ ] cAdvisor integration\n- [ ] Prometheus integration\n- [ ] Grafana integration\n- [ ] Dashboard creation\n\n## Logging\n- [ ] Log collection setup\n- [ ] Log rotation\n- [ ] Centralized log management\n\n## Documentation\n- [ ] README creation\n- [ ] Architecture diagram\n- [ ] Deployment procedures\n- [ ] Troubleshooting"
                },
                "Êú¨Áï™„Éá„Éó„É≠„Ç§„É°„É≥„ÉàÂÆåÂÖ®Áâà": {
                    "title": "Complete Production Deployment",
                    "content": "# compose.prod.yml - Complete Production Environment\nname: ecommerce-prod\n\nnetworks:\n  frontend:\n  backend:\n  monitoring:\n\nservices:\n  # Nginx Reverse Proxy\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n    networks:\n      - frontend\n    restart: unless-stopped\n\n  # React Frontend\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile.prod\n    networks:\n      - frontend\n    read_only: true\n    deploy:\n      replicas: 2\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 256M\n    restart: unless-stopped\n\n  # Node.js API\n  backend:\n    build: ./backend\n    environment:\n      - NODE_ENV=production\n    networks:\n      - frontend\n      - backend\n    healthcheck:\n      test: [\"CMD\", \"node\", \"healthcheck.js\"]\n      interval: 30s\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 512M\n    restart: unless-stopped\n\n  # PostgreSQL\n  postgres:\n    image: postgres:13-alpine\n    volumes:\n      - pg_data:/var/lib/postgresql/data\n    networks:\n      - backend\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready\"]\n    restart: unless-stopped\n\n  # Redis Cache\n  redis:\n    image: redis:7-alpine\n    volumes:\n      - redis_data:/data\n    networks:\n      - backend\n    restart: unless-stopped\n\nvolumes:\n  pg_data:\n  redis_data:"
                },
                "Êú¨Áï™ÈÅãÁî®„ÉÅ„Çß„ÉÉ„ÇØ„É™„Çπ„Éà": {
                    "title": "Production Operations Checklist",
                    "content": "# Production Operations Checklist\n\n## Before Deployment\n\n### Security\n- [ ] Run Trivy scan on all images\n- [ ] Vulnerabilities CRITICAL = 0\n- [ ] Run as non-root user\n- [ ] Secrets management (environment variables/Vault)\n- [ ] TLS/SSL certificate setup\n- [ ] Firewall configuration\n\n### Performance\n- [ ] Resource limits configured\n- [ ] Healthcheck implemented\n- [ ] Log rotation configured\n- [ ] Cache strategy implemented\n- [ ] Database optimization\n\n### Monitoring\n- [ ] Prometheus metrics collection\n- [ ] Grafana dashboard creation\n- [ ] Alert configuration\n- [ ] Log aggregation (Loki/ELK)\n\n### Backup\n- [ ] Database backup automation\n- [ ] Volume backup configuration\n- [ ] Restore procedure verification\n- [ ] RPO/RTO definition\n\n## After Deployment\n\n### Verification\n- [ ] Health check endpoint verification\n- [ ] Load testing\n- [ ] Error rate check\n- [ ] Response time measurement\n\n### Operations\n- [ ] Rolling update procedure verification\n- [ ] Rollback procedure verification\n- [ ] Incident response procedure creation\n- [ ] Documentation maintenance"
                },
                "ÊúÄÁµÇË™≤È°åÔºö„Éó„É≠„ÉÄ„ÇØ„Ç∑„Éß„É≥Áí∞Â¢ÉÊßãÁØâ": {
                    "title": "Final Assignment: Production Environment Setup",
                    "content": "# Final Assignment: Production Environment Setup\n\n## Assignment Overview\nMake E-commerce app ready for production deployment\n\n## Requirements\n\n### 1. Application Architecture\n- Frontend: React (served by Nginx)\n- Backend: Node.js/Express API\n- Database: PostgreSQL\n- Cache: Redis\n\n### 2. Security Requirements\n- [ ] All containers run as non-root\n- [ ] TLS/SSL communication\n- [ ] Secrets management\n- [ ] Trivy scan CRITICAL=0\n- [ ] Rate limiting implementation\n- [ ] CORS configuration\n\n### 3. Monitoring Requirements\n- [ ] Prometheus metrics\n- [ ] Grafana dashboard\n- [ ] Log aggregation\n- [ ] Alert configuration\n\n### 4. CI/CD Requirements\n- [ ] GitHub Actions setup\n- [ ] Automatic tests\n- [ ] Automatic build\n- [ ] Security scanning\n- [ ] Automatic deployment (staging)\n\n### 5. Availability Requirements\n- [ ] Healthcheck implementation\n- [ ] Multiple replicas (Backend: 3 instances)\n- [ ] Database backup\n- [ ] Rolling update support\n\n## Deliverables\n1. Complete source code (GitHub)\n2. docker-compose.prod.yml\n3. GitHub Actions configuration\n4. README.md (setup procedures)\n5. Architecture diagram\n6. Performance test results\n7. Security scan results\n\n## Evaluation Criteria\n- Security: 30 points\n- Availability: 25 points\n- Performance: 20 points\n- CI/CD: 15 points\n- Documentation: 10 points"
                }
            }
        }
    }
}
